SNF_ID,SNF_CHAPTER,SNF_REVIEW_QUESTIONS_ID,SNF_REVIEW_QUESTIONS,SNF_A_COL,SNF_B_COL,SNF_C_COL,SNF_D_COL,SNF_E_COL,SNF_CORRECT_COMBO,SNF_ANSWER_DESCRIPTIONS
SNF_0001,Chapter 1: Introduction and Overview,1,Which of the following are Snowflake editions? (Select all that apply.),A. Standard,B. Enterprise,C. Basic,D. Advanced,E. Business Critical,ABE,Snowflake provides four editions Each edition builds on the features and capabilities of the previous edition The four editions are:_Standard _Enterprise _Business Critical _Virtual Private Snowflake (VPS)
SNF_0002,Chapter 1: Introduction and Overview,2,What is the minimum edition of Snowflake that supports multi-cluster virtual warehouse capability?,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,B,"The Enterprise edition provides all the capabilities of the Standard edition but adds 90 days of Time Travel multicluster virtual warehouses, materialized views, dynamic data masking, and external data tokenization"
SNF_0003,Chapter 1: Introduction and Overview,3,The Standard edition of Snowflake provides how many days of Time Travel?,A. 90,B. 1,C. 45,D. 30,,B,"The Standard edition of Snowflake provides only one day of Time Travel capability Starting with the Enterprise edition, 90 days of Time Travel is available"
SNF_0004,Chapter 1: Introduction and Overview,4,What is the minimum Snowflake edition required for applying masking policies on columns?,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,B,"The Enterprise edition provides all the capabilities of the Standard edition but adds dynamic data masking, 90 days of Time Travel, multicluster virtual warehouses, materialized views, and external data tokenization"
SNF_0005,Chapter 1: Introduction and Overview,5,What is the minimum Snowflake edition required for sharing data?,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,A,Data sharing capabilities are available starting with the Standard edition
SNF_0006,Chapter 1: Introduction and Overview,6,Snowflake is supported on which of the following cloud platforms?(Select all that apply.),A. Amazon Web Services,B. Oracle Cloud,C. Microsoft Azure,D. Google Cloud Platform,E. IBM Cloud Services,ACD,Snowflake is supported on three public cloud platforms: _Amazon Web Services _Microsoft Azure _Google Cloud Platform
SNF_0007,Chapter 1: Introduction and Overview,7,What minimum Snowflake edition supports database replication between Snowflake accounts (within an organization)?,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,A,Data replication is available in the Standard edition
SNF_0008,Chapter 1: Introduction and Overview,8,What is the minimum Snowflake edition required to utilize the search optimization feature for point lookup queries?,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,B,Search optimization is available starting with the Enterprise edition
SNF_0009,Chapter 2: Snowflake Architecture,1,Which of the following terms best describes the architecture of Snowflake?,A. Shared-nothing architecture,B. Shared-disk architecture,C. Hybrid architecture (a mix of shared-nothing compute and shared-disk),"D. Three-tier architecture ",,C,"Snowflake uses a hybrid architecture approach in which the data is stored on a shared-data storage layer but multiple compute clusters can simultaneously perform processing on that data The architecture is often referred to as multicluster, shared-data architecture Another important aspect of this architecture is that the data is independent of the compute"
SNF_0010,Chapter 2: Snowflake Architecture,2,Which of the following is true regarding Snowflake data storage?,A. A Snowflake-based data warehouse can store only up to 100 TB of data.,"B. The capacity of a Snowflake-based data warehouse is nearly unlimited because it is backed by cloud-based storage which itself is nearly unlimited in nature.",C. Snowflake running on an on-premises server can store only 50 TB of data.,"D. A Snowflake-based data warehouse can store only up to 1 PB of data. ",,B,"The cloud object storage is virtually unlimited—you can keep adding data to it, and it is guaranteed that there will always be disk space available to write Since Snowflake uses cloud object storage to store data, the capacity of a Snowflake solution is virtually unlimited There is no limitation on the amount of data you can store in a Snowflake-based solution, and there is no on-premises version of Snowflake, as it is a cloud-only solution"
SNF_0011,Chapter 2: Snowflake Architecture,3,Which of the following statements are true regarding virtual warehouses in Snowflake? (Select all that apply.),A. The term virtual warehouse refers to compute clusters in Snowflake.,B. Only one virtual warehouse can be started at a time.,"C. Virtual warehouses can be suspended resumed and deleted altogether as per the workload requirement.","D. Virtual warehouses can be resized to a smaller or larger size whether in a running state or a suspended state.",,ACD,"Virtual warehouses refer to compute clusters in Snowflake and are used to process queries and load data into Snowflake One or many virtual warehouses can be created and started at the same time When not required, they can be suspended to save costs, and they can be resumed if there are queries or load jobs to be processed They can be deleted altogether if needed A virtual warehouse can also be resized to a smaller or larger size, regardless of whether they are running or suspended It is worth noting that any queries already running on a virtual warehouse are not impacted by the change in size while the virtual warehouse is being resized"
SNF_0012,Chapter 2: Snowflake Architecture,4,A virtual warehouse is resumed from a suspended state and then suspended again within 30 seconds. What is the minimum amount of credits that a virtual warehouse will consume?,A. No Snowflake credits will be consumed.,B. One minute's worth of Snowflake credits.,C. 30 seconds' worth of Snowflake credits.,"D. One hour's worth of Snowflake credits. ",,B,"When a virtual warehouse is resumed, a minimum of one minute's worth of Snowflake credits is consumed, even if the virtual warehouse is suspended before the one minute in the resumed state is reached Once the first minute is passed, the virtual warehouse reverts to per-second billing; for example, if a virtual warehouse were suspended after 1 minute, 45 seconds, 1 minute, 45 seconds' worth of Snowflake credits would be charged But if it was suspended after 35 seconds, a minimum of one minute would apply"
SNF_0013,Chapter 2: Snowflake Architecture,5,Which of the following best describes the Snowflake architecture?,A. Multi-cluster distributed data,B. Single-cluster distributed data,"C. Multi-cluster shared-data","D. Multi-cluster replicated data ",,C,"The architecture for Snowflake is often referred to as multicluster, shared-data architecture This term refers to Snowflake's capability to create many virtual warehouses of the desired configuration providing massively parallel processing capability to Snowflake while still accessing a single shared data"
SNF_0014,Chapter 2: Snowflake Architecture,6,"True or False: As the size of a virtual warehouse increases the amount of Snowflake credit used increases proportionately.""",A. True,"B. False ",,,,A,"Snowflake credit usage is directly proportional to the size of the virtual warehouse The larger the virtual warehouse size, the higher the number of nodes in the virtual warehouse Therefore, a larger virtual warehouse costs more in terms of Snowflake credits used"
SNF_0015,Chapter 2: Snowflake Architecture,7,True or False: A large table in Snowflake may contain millions or hundreds of millions of micro-partitions.,A. True,"B. False ",,,,A,"The number of micro-partitions in a table increases as the size of a table increases For a very large table, the number of micro-partitions can run into millions or hundreds of millions"
SNF_0016,Chapter 2: Snowflake Architecture,8,"True or False: If you create multiple virtual warehouses in a Snowflake-based solution the virtual warehouses share the memory and CPU resources.""",A. True,"B. False ",,,,B,"Virtual warehouses, which are the compute clusters in Snowflake, do not share any memory or CPU resources Each virtual warehouse has its dedicated memory and CPU resources that are not shared with any other virtual warehouse"
SNF_0017,Chapter 2: Snowflake Architecture,9,Snowflake stores which of the following metadata about rows in a micro-partition? (Select all that apply.),A. The range of values for each of the columns in the micro-partition,B. The count of distinct values,C. Additional properties for optimization and efficient processing,"D. List of users who have access to each row ",,ABC,"Snowflake stores the following for each micro-partition in its metadata: Range of values, including Max, Min, and Count Number of distinct values Other optimization metadata"
SNF_0018,Chapter 2: Snowflake Architecture,10,True or False: Snowflake automatically determines the most efficient technique for compressing columns in micro-partitions.,A. True,"B. False ",,,,A,"The columns are compressed in a micro-partition, and Snowflake determines the compression method automatically depending on the column's characteristics"
SNF_0019,Chapter 2: Snowflake Architecture,11,Which of the following statements correctly describes a virtual warehouse in Snowflake?,A. The virtual warehouse is a concept through which two or more physical tables are linked together.,B. Reporting views are called virtual warehouses.,C. Virtual warehouses are the compute cluster(s) that Snowflake uses to execute queries and data load/unload jobs.,"D. Virtual warehouse provide virtualization capabilities. ",,C,"The compute clusters in Snowflake are referred to as virtual warehouses The virtual warehouses are entirely independent of the storage You can have as many or as few of them running simultaneously; however, each virtual warehouse accesses the same shared data"
SNF_0020,Chapter 2: Snowflake Architecture,12,"True or False: At any point in time a virtual warehouse can be suspended or resumed as needed.""",A. True,"B. False ",,,,A,A virtual warehouse may be suspended when it is not being used to save costs and resumed when required A suspended virtual warehouse does not consume any credits and therefore does not cost the customer
SNF_0021,Chapter 2: Snowflake Architecture,13,"True or False: When a virtual warehouse is provisioned terminating it inside the first 60 seconds has no significance because that period has already been billed.""",A. True,"B. False ",,,,A,"When a virtual warehouse is provisioned or resumed, a minimum of one minute's worth of Snowflake credit is immediately consumed, even if the virtual warehouse is suspended before the one minute is reached Once the first minute is passed, the virtual warehouse reverts to per-second billing"
SNF_0022,Chapter 2: Snowflake Architecture,14,"When a virtual warehouse cluster is resized to a smaller size or scaled down extra nodes are removed from the virtual warehouse cluster. Which of the following correctly describes when the extra nodes are removed?""","A. Immediately whether or not a query is using those extra nodes","B. Immediately but only if no query is running on the extra nodes",C. After a delay of one minute,D. When the cluster is suspended or stopped,,B,"When a virtual warehouse is scaled down, nodes are removed from the virtual warehouse only when they are no longer running a query"
SNF_0023,Chapter 2: Snowflake Architecture,15,"True or False: A virtual warehouse may be resized at any moment whether it's in a suspended state or running queries.""",A. True,"B. False ",,,,A,"A virtual warehouse can be resized at any time, whether it is in a suspended state or running queries When a virtual warehouse is resized while in a suspended state, there are no nodes to decommission or provision; therefore, the updated size takes effect only when the virtual warehouse is resumed Snowflake adds or removes new nodes per the new size when a running virtual warehouse is resized The removal of nodes takes place when all active queries on those nodes have finished"
SNF_0024,Chapter 2: Snowflake Architecture,16,"True or False: When a request is made for a virtual warehouse to suspend it enters the suspended state once all active queries on the virtual warehouse have completed execution.""",A. True,"B. False ",,,,A,"When a request is made for a virtual warehouse to suspend, it does not enter a suspended state until all active queries using that virtual warehouse have been completed"
SNF_0025,Chapter 2: Snowflake Architecture,17,Data in Snowflake tables is divided into micro-partitions and stored in a compressed format. What is the size of uncompressed data stored in each micro-partition?,A. 10 MB to 20 MB,B. 20 MB to 50 MB,C. 50 MB to 500 MB,"D. 1 GB to 2 GB ",,C,The correct answer is 50 MB to 500 MB of uncompressed data per micro-partition
SNF_0026,Chapter 2: Snowflake Architecture,18,Data in Snowflake tables is divided into micro-partitions and stored in a compressed format. Which one of the following is a characteristic of micro-partitions?,"A. Micro-partitions are immutable; once written they cannot be changed.",B. A user can control how many micro-partitions are created for a table.,C. A user can specify the size of a micro-partition.,"D. The storage format of a micro-partition can be controlled through configuration. ",,A,"Like the underlying cloud storage, Snowflake partitions are immutable—they cannot be changed once created Therefore, any updates to existing data or loading new data into a table results in new micro-partitions"
SNF_0027,Chapter 2: Snowflake Architecture,19,Which one of the following statements correctly describes data clustering in Snowflake?,"A. Snowflake does not cluster any data and the data is stored in an unclustered form.",B. Snowflake automatically clusters the data as it is inserted into a table.,"C. If a clustering key is not defined Snowflake does not cluster the data.","D. Snowflake clusters the data only when the CLUSTER command is executed. ",,B,Snowflake automatically clusters the data as it is inserted into a table Snowflake automatically clusters the data even if a specific clustering key is not defined
SNF_0028,Chapter 2: Snowflake Architecture,20,Which of the following are layers of Snowflake architecture? (Select all that apply.),A. Cloud services layer,B. Database storage layer,C. Data sharing layer,D. Query processing layer,"E. AWS layer ",ABD,"Snowflake architecture has three distinct layers: Database storage—Inexpensive cloud storage on AWS, Azure, or Google Cloud Query processing—Primarily composed of virtual warehouses Cloud services—The brain of the whole system"
SNF_0029,Chapter 2: Snowflake Architecture,21,How are columns stored within a Snowflake micro-partition?,"A. In a row format with complete rows stored in each micro-partition","B. In a columnar format with each column compressed and stored individually","C. In a CSV format in a comma-separated manner",D. In Parquet format,,B,"Within each micro-partition, Snowflake stores each column in a columnar storage format Each column in a micro-partition is compressed individually Snowflake determines the best and most efficient compression algorithm for each column in each partition Storing data in a columnar format enables Snowflake to optimize the queries by retrieving only the referenced columns"
SNF_0030,Chapter 2: Snowflake Architecture,22,"At a minimum which Snowflake edition is required to create multi-cluster data virtual warehouses?""",A. Standard,B. Enterprise,C. Business Critical,"D. Virtual Private Snowflake ",,B,"multicluster virtual warehouse capability is available starting with the Enterprise edition of Snowflake, but the Standard edition does not have this capability"
SNF_0031,Chapter 3: Interfaces and Connectivity,1,Which of the following connectors and programs can be downloaded from the Downloads section in the Snowflake web UI? (Select all that apply.),A. Go Snowflake driver,B. JDBC driver,C. Snowpipe connector,D. OAuth driver,E. Kerberos driver,AB,Snowflake provides a variety of connectors and drivers Only the Go driver and the JDBC driver are valid examples of programs downloaded through the Snowflake web UI in the given list There is no connector for Snowpipe and no drivers for OAuth or Kerberos
SNF_0032,Chapter 3: Interfaces and Connectivity,2,Consider the Worksheets view on the classic Snowflake web UI. Which of the following can you select for each worksheet? (Select all that apply.),A. Database,B. User,C. Table,D. Schema,E. Virtual Warehouse,ADE,"Each worksheet has its own context under which the query in that worksheet executes These include the Role, the Virtual Warehouse, the Database, and the Schema Each worksheet can have a different context"
SNF_0033,Chapter 3: Interfaces and Connectivity,3,"On the classic Snowflake web UI, which button on the top bar takes you to the screen where you can create new compute clusters?",A. Databases,B. Account,C. Warehouses,D. Worksheets,,C,"The top navigation bar has a button called Warehouses, which a user with the correct privileges can use to create and manage compute clusters, also known as virtual warehouses Warehouses can also be resumed and suspended from this page"
SNF_0034,Chapter 3: Interfaces and Connectivity,4,True or False: You can open only a single worksheet in the Snowflake web UI.,A. True,B. False,,,,B,"You can open several worksheets in the Snowflake web UI simultaneously Each worksheet has its own context under which the query in that worksheet executes These include the Role, the Virtual Warehouse, the Database, and the Schema Each worksheet can have a different context"
SNF_0035,Chapter 3: Interfaces and Connectivity,5,"On the classic Snowflake web UI, which of the following are buttons on the top navigation bar? (Select all that apply.)",A. Worksheets,B. Warehouses,C. Databases,D. Security,,ABC,"Worksheets, Warehouses, and Databases are examples of buttons on the top navigation bar Here is the complete list of buttons available on the top navigation bar: _Databases _Shares _Data Marketplace _Worksheets _History _Account _Snowsight _Partner Connect _Help _Notifications"
SNF_0036,Chapter 3: Interfaces and Connectivity,6,You have logged into the Snowflake web UI but cannot see the Account button in the top bar. Which one of the following could be the reason?,A. Snowflake has renamed the Account button to Organization.,"B. The Account button is only available to users with the ACCOUNTADMIN or SECURITYADMIN role. However, your current role is neither of these two roles.",C. The Account button is shown in only specific browsers.,D. The Account button is shown only for those Snowflake accounts who have the Enterprise license.,,B,"The Account page is one of the essential administrative pages in the classic Snowflake web interface Depending on the role selected on the top-right side of the screen, a user may or may not see the Account page in the navigation bar By default, the Account page is visible only to the built-in ACCOUNTADMIN and SECURITYADMIN roles"
SNF_0037,Chapter 3: Interfaces and Connectivity,7,What functionality can you access under the Warehouses button? (Select all that apply.),A. Review billing and cost information related to virtual warehouses.,B. Create new virtual warehouses.,C. Suspend or resume existing virtual warehouses.,D. See the percentage of space used by each virtual warehouse.,,BC,"On this page, users with the correct privileges can create and manage virtual warehouses Warehouses can also be resumed and suspended from this page Virtual warehouses are computing clusters in Snowflake and can be created, dropped, suspended, and resumed as needed"
SNF_0038,Chapter 3: Interfaces and Connectivity,8,True or False: A Snowflake user can configure multifactor authentication (MFA) through the Snowflake Web UI.,A. True,B. False,,,,A,"A logged-in user can access user preferences at the top-right corner of the navigation bar Through the preferences, users can set up multifactor authentication (MFA)"
SNF_0039,Chapter 3: Interfaces and Connectivity,9,"You are developing a program in Java. The program needs to connect to a Snowflake instance and run queries. To connect to the Snowflake database, which one of the following drivers will you need?",A. Go Snowflake driver,B. JDBC driver,C. Snowpipe connector,D. ODBC driver,E. CLI client (SnowSQL),B,"Snowflake provides a variety of connectors and drivers for various languages and frameworks For Java-based programs, it would be appropriate to use the JDBC driver"
SNF_0040,Chapter 3: Interfaces and Connectivity,10,You plan to use a business intelligence tool to connect to Snowflake to create new reports and dashboards. Which of the following are possible drivers that you can use in the tool to connect to Snowflake? (Select all that apply.),A. Python connector,B. JDBC driver,C. ODBC driver,D. Spark connector,E. CLI client (SnowSQL),BC,"ODBC and JDBC are the prevalent methods of connecting tools to databases Snowflake provides drivers for both JDBC- and ODBC-based connectivity Depending on what your business intelligence tool supports, you can use the ODBC or JDBC drivers to connect to Snowflake"
SNF_0041,Chapter 3: Interfaces and Connectivity,11,Which type of Snowflake partner is Matillion?,A. Data Integration,B. Business intelligence,C. Machine learning and data science,D. SQL development and management,E. Security and governance,A,"Matillion is a data integration partner To see a list of all Snowflake partners and their categorization, visit _https://docs snowflake com/en/user-guide/ecosystem-all html"
SNF_0042,Chapter 4: Loading Data,1,Which of the following features in Snowflake allows creating tables through which you can query data in an external stage without loading it first?,A. Materialized views,B. External tables,C. Snowpipe,D. COPY,,B,Snowflake provides an alternative approach called external tables to query data in external cloud storage External tables can be queried like regular tables They can be connected to other tables and have views developed on them
SNF_0043,Chapter 4: Loading Data,2,True or False: Snowpipe is designed to load small volumes of data that is arriving continuously.,A. True,B. False,,,,A,"Snowflake supports the loading of continuous data through a serverless service called Snowpipe Snowpipe allows you to load data in micro-batches It is typically utilized when a steady stream of small data must be loaded, such as transactions or events"
SNF_0044,Chapter 4: Loading Data,3,Which of the following statements are true for external tables?(Choose three.),A. External tables can be joined with other tables.,B. Views can be created on external tables.,C. Update queries can be run on external tables.,D. External tables are read-only.,,ABD,"External tables can be queried the same way a standard table is queried They can be joined to other tables, and views can be created on an external table External tables are read-only since they point to an external storage location; therefore, DML or update operations cannot be performed on an external table"
SNF_0045,Chapter 4: Loading Data,4,Which of the following statements are true for Snowpipe? (Choose two.),A. Snowpipe uses an active virtual warehouse to load data.,B. Snowpipe makes use of Snowflake's serverless computing resources.,C. Snowflake automatically scales up and down the Snowpipe resource.,D. Snowpipe's compute resources are managed through a virtual warehouse that you must expand yourself.,,BC,"Snowpipe is serverless and is managed, scaled up, and scaled down automatically without requiring any intervention from the user Costs for Snowpipe are charged separately from virtual warehouse costs"
SNF_0046,Chapter 4: Loading Data,5,Which of the following is true about Snowpipe? (Choose two.),A. The cost of Snowpipe is calculated and billed separately from the cost of virtual warehouse use.,B. Snowpipe utilizes shared virtual warehouse computational resources for processing.,C. Snowpipe is serverless and so does not require virtual warehouse resources.,D. Snowpipe consumption costs are included in the virtual warehouse compute.,,AC,Snowpipe does not rely on virtual warehouses for processing because it is serverless and has its own compute power Snowflake takes care of the Snowpipe's computational capacity and scaling up and down automatically A Snowpipe's cost is billed separately from the costs of a virtual warehouse
SNF_0047,Chapter 4: Loading Data,6,Which one of the following data loading methods uses virtual warehouse resources? (Choose all that apply.),A. Loading data using COPY command through an external stage,B. Loading data using COPY command through an internal stage,C. Data loading through Snowpipe,D. Unloading data to an external stage using the COPY command,,ABD,"The COPY command requires a virtual warehouse to execute Snowpipe is serverless and has its own compute capacity, which means that Snowpipe doesn't depend on virtual warehouses for processing"
SNF_0048,Chapter 4: Loading Data,7,Which of the following can be used to load data using the COPY command? (Choose two.),A. External stage,B. Internal stage,C. Web pages,D. REST APIs,,AB,"Stages help load and unload data in Snowflake To process data into a Snowflake table, it must first be available in a Snowflake stage Once the data is staged, it may be copied into a table using the COPY command Broadly, the two types of stages in Snowflake are external stages and internal stages"
SNF_0049,Chapter 4: Loading Data,8,Snowflake supports which semi-structured file formats? (Choose all that apply.),A. Parquet,B. JSON,C. HTML,D. Avro,E. XML,ABDE,"Snowflake provides built-in support for handling a variety of semi-structured data formats, among them JSON, Avro, ORC, Parquet, and XML"
SNF_0050,Chapter 4: Loading Data,9,"When exporting or unloading data from Snowflake, which of the following file formats are supported for unloading? (Choose all that apply.)",A. Avro,B. ORC,C. XML,D. CSV,E. Parquet,DE,"Snowflake supports the following file formats for unloading data: _Delimited text files—CSV, TSV _JSON—NDJSON only _Parquet The following file formats cannot be used to export data but can be used to load data: _Avro _ORC _XML"
SNF_0051,Chapter 4: Loading Data,10,What is the amount of uncompressed data that a column of VARIANT data type can store for a single row?,A. 8 MB,B. 16 MB,C. Unlimited,D. 32 MB,,B,The VARIANT data type can store any data type and can store up to 16 MB of uncompressed data for each row
SNF_0052,Chapter 4: Loading Data,11,The load metadata for a table expires after how many days?,A. 64 days,B. 32 days,C. Never,D. 256 days,,A,"The load metadata includes information such as the name of each file loaded into that table and the time stamp for the file's most recent load Snowflake uses this load metadata to ensure that it does not reprocess a file that has already been loaded After 64 days, the load metadata expires"
SNF_0053,Chapter 4: Loading Data,12,Which of the following can be a target location when using the COPY INTO <location> command? (Choose two.),A. A named internal stage,B. A named external stage,C. A local folder,"D. Cloud storage location, such as an S3 bucket",,AB,"Data from tables and views can be extracted to Snowflake's internal and external stages through the COPY command The GET command can be used to download data from an internal stage to your PC Data extracted to external stages is often accessible via cloud storage access techniques, such as directly accessing the S3 bucket that the external stage referenced"
SNF_0054,Chapter 4: Loading Data,13,Which of the following statements are true regarding data loading? (Choose all that apply.),A. GET is used to download files from a Snowflake internal stage to a local folder.,B. PUT is used to upload files into a Snowflake internal stage from a local folder.,C. REMOVE can be used to remove files from internal stages and external stages.,D. GET and PUT cannot be executed from the Worksheets view.,E. LOAD is used to load files into a table from an internal stage.,ABCD,"Data from tables and views can be extracted to Snowflake's internal and external stages through the COPY command Once the data is in an internal stage, it can be downloaded to your computer using the GET command Data must be uploaded to internal stages through the PUT command using SnowSQL REMOVE can be used to delete files from Snowflake's internal stages and external stages The GET and PUT commands cannot be run from the Worksheets view but are generally run from a client utility such as SnowSQL"
SNF_0055,Chapter 4: Loading Data,14,Which of the following transformations are not supported by the COPY command? (Choose three.),A. JOIN,B. GROUP BY,C. FLATTEN,D. CONCAT,E. CAST,ABC,"The COPY command doesn't support joins, filtering, or aggregations Snowflake allows you to apply basic transformations to data while loading it into a table The COPY command supports changing the order of columns, omitting one or more columns altogether, and casting data into specific data types during the ingestion process The COPY command also supports truncating data that exceeds the target column width"
SNF_0056,Chapter 4: Loading Data,15,Snowpipe supports loading data continuously. Snowpipe can load data from which of the following objects? (Choose two.),A. External stages,B. Internal stages,C. Temporary tables,D. Transient tables,,AB,Snowpipe can load data from external or internal stages You must trigger a Snowpipe through the REST API when using internal stages with Snowpipe
SNF_0057,Chapter 4: Loading Data,16,"True or False: When you use the PUT command, the data is encrypted on the client machine before uploading it.",A. False,B. True,,,,B,"All data files loaded to a Snowflake internal stage are encrypted automatically using 256-bit encryption They are encrypted by the client program, like SnowSQL, before being uploaded to a Snowflake stage"
SNF_0058,Chapter 4: Loading Data,17,What is the recommended file size to optimize the load process?,A. 100–250 MB,B. 25–50 MB,C. 5–10 MB,D. 500 MB,,A,"For optimal loading performance through the COPY command, it is recommended to have the file size approximately 100–250 MB after compression This applies both to regular loads and for data loaded through Snowpipe"
SNF_0059,Chapter 5: Data Pipelines,1,Which of the following is a way to view task execution history for tasks that use a user-managed virtual warehouse?,A. SELECT task_execution_history from the session.,B. Query the task_execution_history table in the system schema.,C. Query the information_schema.task_history() table function.,D. It is not possible to view the task execution history.,,C,The history of user-managed tasks' execution can be found by using the task_history() table function This function returns the last 7 days of the history of executed task and the scheduled executions within the next 8 days
SNF_0060,Chapter 5: Data Pipelines,2,Which of the following privileges is required to set a task to resumed state?,A. EDIT TASK privilege,B. EXECUTE TASK privilege,C. RESUME TASK privilege,D. ADMIN TASK privilege,,B,Only roles with the EXECUTE TASK privilege can resume a task
SNF_0061,Chapter 5: Data Pipelines,3,Which of the following are valid scheduling approaches for tasks? (Choose all that apply.),A. ON EVENT,B. Using CRON,C. <num> MINUTE,D. ON DATE,,BC,Snowflake tasks can be scheduled using CRON expressions or a more straightforward approach by providing the number of minutes after which the task will execute
SNF_0062,Chapter 5: Data Pipelines,4,You have just created a new task. What would be the initial state of this task?,A. Suspended,B. Active,C. Resumed,D. Running,,A,Newly created tasks are created in a suspended state and must be set to resume for them to start executing according to the defined schedule Only roles with the EXECUTE TASK privilege can resume a task
SNF_0063,Chapter 5: Data Pipelines,5,Which of the following is true regarding task trees? (Choose all that apply.),A. Multiple tasks connected in a parent-child relationship form a task tree.,B. Only the root node can have a schedule in a task tree.,C. Tasks can have multiple parents.,D. All tasks in a tree of tasks must have the same task owner.,,ABD,"Numerous Snowflake tasks can be linked together in a tree-like structure with a single root node and multiple child nodes The task tree starts with a root node and has one or more child tasks There can only be one parent task per task; however, one parent task can have several child tasks All tasks in a tree of tasks must have the same task owner—that is, the OWNER privilege on all tasks in the tree must be held by the same role"
SNF_0064,Chapter 5: Data Pipelines,6,Which of the following is true regarding serverless tasks? (Choose all that apply.),A. Serverless tasks use Snowflake-managed compute resources.,B. Serverless tasks are billed differently and have a 1.5 multiplier when calculating credit usage.,C. Snowflake scales the compute up and down for serverless tasks as per workload requirements.,D. Serverless tasks cannot have any child tasks.,,ABC,"The serverless tasks let you leverage Snowflake-managed compute resources for task execution Snowflake may scale the computational resources up or down as needed, depending on the workload demands of each task To offset the administration costs of serverless operations, Snowflake applies a 1 5 multiplier to the Snowflake credit computation"
SNF_0065,Chapter 5: Data Pipelines,7,Streams are a Snowflake mechanism that provides which of the following functionalities?,A. Message queue capabilities,B. Change data capture,C. Data archival,D. Scheduled execution of SQL,,B,"Snowflake's streams feature helps you keep track of data modifications to a table Any data changes made to a table, including inserts, updates, and deletes, can be tracked using a stream Change data capture (CDC) is a method that allows users and processes to determine what has changed in a table since the last time they consumed it"
SNF_0066,Chapter 5: Data Pipelines,8,Streams can capture which of the following changes in a table? (Choose all that apply.),A. INSERTs,B. UDPDATEs,C. DELETEs,D. Table structure changes,E. Table name changes,ABC,"A stream can track any data changes made to a table's data, including inserts, updates, and deletes"
SNF_0067,Chapter 5: Data Pipelines,9,Which of the following is true regarding streams? (Choose all that apply.),A. Streams can be queried like a table.,"B. Once a stream is created, it cannot be dropped unless the whole table is dropped.",C. Multiple streams can be created on the same table.,D. Streams don't contain any data but are bookmarks to the data changes.,,ACD,"Streams can be queried in the same way that tables are, allowing users to read and process data from a stream in the same way they can read and process data from a table Think of streams as bookmarks that encapsulate changes and advances to point to future changes as they occur after you have consumed the most recent updates"
SNF_0068,Chapter 6: Continuous Data Protection,1,Which of the following Snowflake editions provide Time Travel capability? (Choose all that apply.),A. Enterprise,B. Standard,C. Business Critical,D. Virtual Private Snowflake,,ABCD,"All Snowflake editions provide Time Travel capability The Standard edition provides only one day of Time Travel, and from the Enterprise edition upward, 90 days of Time Travel is provided"
SNF_0069,Chapter 6: Continuous Data Protection,2,Which of the following is the minimum Snowflake edition that provides 90 days of Time Travel?,A. Enterprise,B. Standard,C. Business Critical,D. Virtual Private Snowflake,,A,Enterprise is the minimum Snowflake edition that provides 90 days of Time Travel
SNF_0070,Chapter 6: Continuous Data Protection,3,"True or False: Time Travel requires extra storage, which results in additional costs.",A. True,B. False,,,,A,True Snowflake charges for data storage for Time Travel and Fail-safe storage purposes Costs for storage are incurred because historical micro-partitions are kept to enable Time Travel and Fail-safe functioning
SNF_0071,Chapter 6: Continuous Data Protection,4,What is the maximum amount of Time Travel duration possible when using Snowflake Standard edition?,A. 7 days,B. 90 days,C. One day,D. Zero days,,C,The Standard edition provides only one day of Time Travel
SNF_0072,Chapter 6: Continuous Data Protection,5,What is the maximum amount of Time Travel possible for a temporary table?,A. 7 days,B. 90 days,C. One day,D. Zero days,,C,Temporary tables are limited to one day of Time Travel and do not include a Fail-safe period
SNF_0073,Chapter 6: Continuous Data Protection,6,Which of the following table types don't provide any Fail-safe storage? (Choose all that apply.),A. Permanent tables,B. Temporary tables,C. Transient tables,D. Aggregate tables,,BC,"For those who want to avoid the costs associated with Time Travel and Fail-safe storage, Snowflake supports two table types: temporary tables and transient tables Both table types do not support Fail-safe storage Additionally, temporary and transient tables allow only one day of Time Travel, which helps to keep costs down"
SNF_0074,Chapter 6: Continuous Data Protection,7,Data that has entered Fail-safe storage can be accessed by which of the following?,A. Any user,B. Snowflake support,C. IT staff,D. Administrators,,B,"Only Snowflake support can recover data that is in Fail-safe mode For example, Snowflake support can leverage the Fail-safe storage to restore data in severe cases when data has been lost or destroyed due to unanticipated failures"
SNF_0075,Chapter 6: Continuous Data Protection,8,What is the maximum amount of Time Travel possible for a transient table?,A. 7 days,B. 90 days,C. 1 day,D. 0 days,,C,Transient tables are limited to one day of Time Travel and do not include a Fail-safe period
SNF_0076,Chapter 6: Continuous Data Protection,9,What is the maximum allowable duration for Time Travel for a permanent table in the Snowflake Enterprise edition?,A. 7 days,B. 90 days,C. 0 days,D. One day,,B,Enterprise edition allows 90 days of Time Travel for permanent tables Business Critical and Virtual Private Snowflake also allow 90 days of Time Travel The Standard edition only has up to one day of Time Travel for permanent tables
SNF_0077,Chapter 6: Continuous Data Protection,10,"True or False: It is possible to disable Fail-safe for certain databases, schemas, or tables.",A. True,B. False,,,,B,"Fail-safe cannot be turned off for an account, a database, or a table Instead, it is an ever-present Snowflake feature Transient and temporary tables are the only types of tables in Snowflake that do not have Fail-safe protection by default"
SNF_0078,Chapter 6: Continuous Data Protection,11,True or False: Fail-safe storage is a way for Snowflake customers to access historical data that may have been accidentally deleted.,A. False,B. True,,,,A,"Fail-safe storage can only be accessed by Snowflake support Unlike with data in Time Travel, a Snowflake customer cannot access data in Fail-safe storage"
SNF_0079,Chapter 6: Continuous Data Protection,12,Which of the following objects can be undropped? (Choose all that apply.),A. Databases,B. Tables,C. Schemas,D. External stages,E. File formats,ABC,"Databases, schemas, and tables can be undropped When databases or schemas are undropped, their child objects, such as views and tables, are also undropped"
SNF_0080,Chapter 7: Cloning and Data Sharing,1,Which of the following are true regarding cloned tables? (Select all that apply.),A. Cloning physically copies data from one table to another.,B. A cloned table does not contribute to the overall storage.,C. Cloning is a metadata operation.,D. Cloning is almost instantaneous.,,BCD,"Snowflake's cloning capability allows users to duplicate a table, schema, or database without physically transferring the data Cloning doesn't require extra storage because data isn't copied Because cloning does not duplicate data physically, the operation is substantially faster as compared to physically copying data"
SNF_0081,Chapter 7: Cloning and Data Sharing,2,True or False: Cloning is a metadata operation.,A. True,B. False,,,,A,"No micro-partitions are copied during zero-copy cloning; the cloned table is pointed to the existing micro-partitions via metadata The cloned table shares the source table's micro-partitions This is a metadata-only operation; thus, no data movement or additional storage is required"
SNF_0082,Chapter 7: Cloning and Data Sharing,3,Which of the following can be cloned? (Select all that apply.),A. Databases,B. Schemas,C. Tables,,,ABC,"All of these are examples of objects that can be cloned Zero-copy cloning can be performed for a table or even at a schema or a database level When a complete database is cloned, child objects in that database (including children schema) are made available in the clone When a schema is cloned, its child objects are cloned and made available in the cloned schema Certain objects cannot be cloned, such as external tables"
SNF_0083,Chapter 7: Cloning and Data Sharing,4,"True or False: After cloning, any updates to the cloned table automatically update the source table.",A. True,B. False,,,,B,"Zero-copy clones of a table point to the same micro-partitions as the source table However, after a table is cloned, the two tables exist independently—updates, inserts, and deletes can be performed to either table, and they do not impact each other"
SNF_0084,Chapter 7: Cloning and Data Sharing,5,Which of the following are true regarding cloning? (Select all that apply.),A. Cloning a database does not copy any of its child schemas or their objects.,B. Cloning a database copies all of its child schemas and their objects.,C. A database cannot be cloned.,"D. If a database or schema is cloned, child object privileges are copied.",,BD,"When you clone a database, all of its child schemas and the objects contained within those schemas are also cloned When a database or schema is cloned, only the privileges on the child objects are copied However, a cloned object does not inherit any of the privileges from the source object"
SNF_0085,Chapter 7: Cloning and Data Sharing,6,Which of the following is correct regarding cloning? (Select all that apply.),A. Internal named stages cannot be cloned.,B. A Snowflake account can be cloned.,"C. When a database or schema is cloned, any Snowpipes that reference an internal named stage are not cloned.",,,AC,Cloning internal named stages is not possible Snowpipes that reference an internal named stage are not cloned when a database or schema is cloned
SNF_0086,Chapter 7: Cloning and Data Sharing,7,Which of the following are Snowflake's product offerings for Secure Data Sharing? (Select all that apply.),A. Direct Sharing,B. Data Monetization,C. Snowflake Data Marketplace,D. Data Exchange,,ACD,"Snowflake's data sharing offerings include Direct Sharing, Snowflake Data Marketplace, and Data Exchange"
SNF_0087,Chapter 7: Cloning and Data Sharing,8,"A data provider has shared a set of tables with a consumer through a share. The consumer has created a read-only database on the share and can successfully see and read the table data. If the data provider adds new tables to the share, which of the following statements apply?",A. The consumer is required to drop and re-create the database on the share to see the new tables.,B. The new tables automatically appear in the read-only database.,C. It is not possible to add tables to a share after it has been shared with a consumer.,,,B,"After a share has been granted to a consumer and the consumer has created a read-only database on the share, all new objects added to the share by the provider automatically become accessible to the consumer"
SNF_0088,Chapter 7: Cloning and Data Sharing,9,A data provider has shared a set of tables with a data consumer who is a Snowflake customer. Who is billed for the compute usage when the consumer runs queries on the shared data?,A. The data provider,B. The data consumer,,,,B,"The consumer account is responsible for paying for the compute resources used to conduct queries on the data shared with them The only exception is reader accounts, which are created by a data provider and billed to the provider"
SNF_0089,Chapter 7: Cloning and Data Sharing,10,A data provider has shared a set of tables with a non-Snowflake user. The data provider created a reader account to enable the sharing. Who is billed for the compute usage when the consumer runs queries on the shared data?,A. The data provider,B. The data consumer,,,,A,"The provider account is responsible for the compute cost on reader accounts Data providers create and own reader accounts, and therefore, the management and costs associated with reader accounts are billed to the creating/provider account"
SNF_0090,Chapter 7: Cloning and Data Sharing,11,Is it possible to add multiple consuming accounts to a single share?,A. Yes,B. Only if you are an Enterprise customer,C. No,D. Only when using AWS as the cloud provider,,A,"It is possible to add multiple consumer accounts to a single share, simultaneously sharing the data with several consumers There is no limitation regarding the Snowflake edition or the cloud provider"
SNF_0091,Chapter 7: Cloning and Data Sharing,12,Which of the following roles can create a Share in Snowflake? (Select all that apply.),A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. A role that has been granted the CREATE SHARE privilege,,AD,A share can be created only by the ACCOUNTADMIN role or roles that have been explicitly granted the CREATE SHARE privilege
SNF_0092,Chapter 7: Cloning and Data Sharing,13,Which of the following roles can create a read-only database from a share in Snowflake? (Select all that apply.),A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. A role that has been granted the IMPORT SHARE privilege,,AD,"As a consumer account, a read-only database on the share can be created only by the ACCOUNTADMIN role or roles that have been explicitly granted the IMPORT SHARE privilege"
SNF_0093,Chapter 7: Cloning and Data Sharing,14,Which of the following is true regarding Data Exchange in Snowflake? (Select all that apply.),A. Data Exchange is your own private data sharing hub where you can share data with an invite-only group of people and organizations.,"B. Participating members can share, consume, or do both, depending on their privileges.",C. The account owning the Data Exchange is responsible for inviting members.,"D. Data Exchange allows businesses to share data among a limited set of trustworthy partners, suppliers, vendors, and customers.",,ABCD,"All of this is true Data Exchange is a private data sharing hub where you can share data with a small number of people The Data Exchange owner invites members and specifies whether they can share, consume, or do both Data sharing allows businesses to share data with trustworthy partners, providers, and customers"
SNF_0094,Chapter 7: Cloning and Data Sharing,15,Which of the following is true regarding Data Marketplace in Snowflake? (Select all that apply.),A. Snowflake accounts can also publish and monetize datasets on the Marketplace.,B. Snowflake Data Marketplace is a marketplace for discovering and gaining access to third-party datasets made available by various organizations.,C. The third-party datasets on Data Marketplace are always free.,"D. Except for VPS Snowflake accounts, all Snowflake accounts have access to the Snowflake Data Marketplace.",,ABD,Snowflake Data Marketplace is a marketplace for discovering and gaining access to third-party datasets made available by diverse organizations These third-party datasets are frequently supplied for a fee but can be offered free Snowflake accounts can also publish and monetize datasets on the Marketplace
SNF_0095,Chapter 8: Performance,1,Which of the following is true when a virtual warehouse is scaled up to a larger size? (Choose all that apply.),A. Charging for the new size does not begin until all the new nodes in the larger virtual warehouse have been provisioned.,B. Charging for the new size begins immediately.,C. Any queries that were already running on the virtual warehouse do not benefit from the new size.,D. Only new queries can take advantage of the increased cluster size.,E. A virtual warehouse cannot be scaled up if there are any active queries on the virtual warehouse.,ACD,"When a virtual warehouse is scaled up, billing for the larger virtual warehouse does not begin until all the additional nodes in the larger virtual warehouse have been provisioned Only new queries benefit from the increased size; existing queries in the virtual warehouse are unaffected A virtual warehouse can be scaled up at any time whether or not queries are running on that virtual warehouse"
SNF_0096,Chapter 8: Performance,2,Which of the following is true when a virtual warehouse is scaled down to a smaller size? (Choose all that apply.),"A. When a virtual warehouse is scaled down, nodes are withdrawn from the compute cluster.","B. When a virtual warehouse is scaled down, nodes are removed only when there are no active queries on the nodes that are to be removed.",C. The decrease in size does not impact any queries that were already running on the virtual warehouse.,,,ABC,All of these are true when a virtual warehouse is scaled down Nodes are removed from the compute cluster when a virtual warehouse is scaled down Nodes are removed only when there are no active queries on the virtual warehouse
SNF_0097,Chapter 8: Performance,3,Scaling up a virtual warehouse to a larger size is suitable for which of the following scenarios?,A. There are a large number of concurrent users on the system.,B. There are a large number of concurrent queries on the system.,C. Complex queries are running on the system and are required to finish faster.,,,C,"A virtual warehouse may be scaled up or down based on the complexity of the queries and the required performance In general, increasing the size of the virtual warehouse improves query speed for particular CPU-intensive queries However, scaling up does not help with a large number of users or a large number of queries A multi-cluster virtual warehouse (scaling out) is used to cater to an increased number of users and queries"
SNF_0098,Chapter 8: Performance,4,Which of the following statements describe scaling out in Snowflake? (Choose all that apply.),A. Scaling out is achieved by using multi-cluster virtual warehouses.,B. Scaling out is achieved by increasing or decreasing a virtual warehouse size.,C. Scaling out can help reduce query queuing.,,,AC,"A single virtual warehouse may handle up to eight concurrent requests by default When the concurrent workload for a specific virtual warehouse exceeds the limit, additional queries are queued This issue is solved by multicluster virtual warehouses, which add new clusters dynamically based on demand This is also known as scaling out or autoscaling"
SNF_0099,Chapter 8: Performance,5,What is the minimum Snowflake edition that supports multi-cluster virtual warehouses?,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,B,A minimum of Snowflake Enterprise edition is required to use the multicluster virtual warehouse capabilities
SNF_0100,Chapter 8: Performance,6,Which of the following scaling policies aims to minimize query queuing?,A. Standard,B. Economy,,,,A,"The Standard scaling policy minimizes queuing by starting additional warehouses as soon as it detects query queuing The Economy scaling policy allows queuing to occur for some time before scaling out, saving costs over performance"
SNF_0101,Chapter 8: Performance,7,Consider the following configuration and select the mode of operation for this multi-cluster virtual warehouse. Minimum cluster count = 2 Maximum cluster count = 5 Size = Large,A. Maximized,B. Autoscale,,,,B,Set the cluster's minimum and maximum warehouse count to different values to allow autoscaling Snowflake thus starts and stops warehouses dependent on the workload Set the cluster's minimum and maximum warehouse counts to the same value to enable maximized mode So all warehouses in the cluster are started when the multi-cluster virtual warehouse starts
SNF_0102,Chapter 8: Performance,8,Which of the following statements are true regarding a multi-cluster virtual warehouse in autoscale mode?,A. Additional warehouses are started up when Snowflake detects that queries are starting to queue.,B. Warehouses are progressively shut down when the query demand reduces.,"C. Multi-cluster virtual warehouses support all the properties and actions as regular virtual warehouses. They can be suspended, resumed, and reconfigured to be of a different size.","D. Once a multi-cluster virtual warehouse is created, its configuration cannot be changed. It cannot be suspended or resumed.",,ABC,"When a multicluster virtual warehouse using autoscaling mode is started, the number of active virtual warehouses is equal to the minimum warehouse count Snowflake spins up additional warehouses based on the demand, up to the maximum warehouse count As the demand reduces, Snowflake shuts down virtual warehouses until the number is equal to the minimum warehouse count multicluster virtual warehouses support the standard virtual warehouse properties and actions, including specifying and changing warehouse size, suspending or automatically suspending, resuming, or automatically resuming a suspended multicluster virtual warehouse"
SNF_0103,Chapter 8: Performance,9,Which of the following conditions must be met for Snowflake to reuse the query result cache for a query? (Choose all that apply.),A. The query does not use runtime functions.,B. The underlying data contributing to the query results has not changed.,C. A new query matches an old query.,D. Reclustering or consolidation has not changed the table micro-partitions.,E. Neither user-defined nor external functions are used in the query.,ABCDE,"All of these are true If the following conditions are met, Snowflake uses the query result cache: A new query matches an old query, and the underlying data contributing to the query results has not changed Due to clustering or consolidation, the table micro-partitions have not changed The query does not use user-defined or external functions or runtime functions However, queries using the CURRENT_DATE function are eligible for query result caching"
SNF_0104,Chapter 8: Performance,10,Which of the following are true regarding the query result cache? (Choose all that apply.),A. The query result cache is used if an identical query is run within a 24-hour period of the original query (that produced the query result cache).,B. The maximum number of days for which a query result cache may be retained is 31 days.,C. The query result cache is stored in virtual warehouse SSD storage.,D. The query result cache is stored in the cloud services layer.,E. The query result cache is purged if it is not reused within 24 hours.,ABDE,"The query result cache is valid for 24 hours During those 24 hours, if a new query matching the previous query is run, the results are returned from the query result cache The query result cache is stored in the cloud services layer and can be used to return query results for any user A query's result cache is initially valid for 24 hours, but it is valid for another 24 hours when a new query uses it This extension can last up to 31 days, after which it is purged The query result cache is purged after 24 hours if not used"
SNF_0105,Chapter 8: Performance,11,Which of the following are examples of caches in Snowflake? (Choose all that apply.),A. Query result cache,B. Cloud platform cache,C. Virtual warehouse cache,D. Metadata cache,E. High-speed cache,ACD,"The Snowflake caching system improves query performance If the query simply counts rows or finds the minimum or maximum value for a column, the metadata cache can provide the results The metadata cache keeps statistics for each table, micro-partition, and column If the query has already been run and the data hasn't changed, Snowflake can return the results from the query result cache Each virtual warehouse also has its own cache, built by copying micro-partitions from cloud storage to SSD storage over time Similar queries executed on a virtual warehouse may already have some data in the cache, improving query performance"
SNF_0106,Chapter 8: Performance,12,"To process SQL queries, a virtual warehouse must generally be running. Which types of queries can produce results without the need for a running virtual warehouse? (Choose all that apply.)",A. Queries that have previously been run and have produced a result cache,"B. Queries such as count of rows, minimum and maximum for a column",C. Queries that produce less than 100 MB of a result set,D. Queries that use only one table,,AB,"When Snowflake executes a query, it caches the result of that query for a period of time The query result cache returns results for future identical queries without reexecuting the query and an active virtual warehouse Snowflake can also fulfill COUNT, MIN, and MAX queries using the metadata cache and doesn't require an active warehouse for such queries"
SNF_0107,Chapter 8: Performance,13,Which of the following caches are stored in the cloud services layer? (Choose all that apply.),A. Query result cache,B. Metadata cache,C. Virtual warehouse cache,D. Browser cache,E. SnowSQL cache,AB,The query result cache and the metadata cache are stored in the cloud services layer The virtual warehouse cache is stored in a virtual warehouse SSD storage and is purged when a virtual warehouse is shut down A browser cache and SnowSQL cache are not examples of valid caching mechanisms in Snowflake
SNF_0108,Chapter 8: Performance,14,How does clustering keys improve query performance?,A. By precalculating query results and physically storing them,B. By compressing data in columns,C. By distributing data in micro-partitions such that a more optimized partition pruning can occur during query execution,D. By distributing the data over multiple compute clusters so that each computer cluster has a subset of data to process,,C,"For tables with a clustering key, Snowflake redistributes data in micro-partitions according to the clustering key The redistribution of data into new micro-partitions ensures optimal partition pruning"
SNF_0109,Chapter 8: Performance,15,Which of the following are true regarding materialized views? (Choose all that apply.),A. A materialized view automatically updates when the underlying table's data changes.,B. Materialized views are used to improve query performance. They precompute query results and store the results physically.,C. A materialized view can provide precomputed results that can fulfill some queries much faster.,"D. Materialized views are automatically maintained by a Snowflake service running in the background, transparent to the users.",,ABCD,"All of these are true statements To improve query performance, materialized views precompute and store query results physically The performance gains can be significant if the query benefiting from materialization is complex or executed frequently As the underlying table is updated, the materialized view automatically updates Snowflake manages a background service that performs the update invisibly to the user Therefore, data in a materialized view is always in sync with data in its base table"
SNF_0110,Chapter 9: Security,1,Snowflake supports which of the following security features? (Select all that apply.),A. AES 256 encryption of data at rest,B. MD5 encryption of data at rest,C. Tri-Secret Secure encryption,D. Key rotation,,ACD,"By default, Snowflake encrypts all customer data using AES-256 bit encryption Snowflake rotates Snowflake-managed keys automatically after 30 days Tri-Secret Secure is the term used to describe the combination of a Snowflake managed key and a customer-managed key that creates a composite master key that protects your data"
SNF_0111,Chapter 9: Security,2,What is the minimum Snowflake edition that supports Tri-Secret Secure encryption?,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,C,Tri-Secret Secure requires a minimum of the Business Critical edition and can be enabled by contacting Snowflake support
SNF_0112,Chapter 9: Security,3,Which of the following statements are true regarding Snowflake's multifactor authentication (MFA)? (Select all that apply.),A. MFA is provided only in the Business Critical and above editions.,B. MFA is only supported by the Snowflake web interface and SnowSQL.,"C. MFA is enabled for all users by default; however, users need to enroll themselves into MFA manually.",D. An administrator can disable MFA for a user.,,CD,"MFA is enabled by default for all Snowflake accounts, and any Snowflake user can enroll themselves in MFA via the Snowflake web interface A user's MFA enrollment can be disabled by an administrator, in which case the user must re-enroll in MFA to take advantage of the MFA capabilities SnowSQL, Snowflake ODBC, JDBC, and Python Connector all support MFA MFA is available for all editions of Snowflake"
SNF_0113,Chapter 9: Security,4,Snowflake supports which of the following authentication mechanisms? (Select all that apply.),A. Key pair authentication,B. Multifactor authentication,C. SAML 2.0 federated authentication,D. Google Authentication,,ABC,"Key pair authentication, which Snowflake supports, is a more secure alternative to the standard username/password authentication mechanism Snowflake also offers multifactor authentication to add an extra layer of security to the login process Snowflake supports federated authentication, enabling users to log in using single sign-on (SSO) Users authenticate via SSO-enabled authentication via an external identity provider (IdP) that adheres to the SAML 2 0 standard"
SNF_0114,Chapter 9: Security,5,Which of the following is true regarding key pair authentication in Snowflake? (Select all that apply.),A. A user can be assigned up to two public keys.,B. Key pair authentication requires providing your Snowflake username and password when prompted.,C. The keys can be rotated if desired.,D. Key pair authentication is available only for the VPS edition.,,AC,"Snowflake supports key pair authentication as an alternative to conventional username/password login for added protection This approach uses private and public keys, with the user having a public key and using it to authenticate A user can have up to two public keys at a time, which can be rotated All SnowSQL and Snowflake drivers and connectors enable key pair authentication"
SNF_0115,Chapter 9: Security,6,Which of the following statements are true regarding federated authentication in Snowflake? (Select all that apply.),A. Snowflake supports most SAML 2.0 identity providers.,"B. Once authenticated by an external identity provider, a user does not need to provide a Snowflake username.",C. Users need to provide a Snowflake username and password after being authenticated by an external identity provider.,D. Snowflake has native support for Okta and ADFS.,,ABD,"Snowflake supports federated authentication, allowing single sign-on (SSO) Users authenticate via an external identity provider (IdP) that supports SAML 2 0 Users can access Snowflake without logging in after IdP authentication For example, Snowflake supports most SAML 2 0–compliant identity providers such as Okta and ADFS natively, as well as OneLogin and Ping Identity PingOne"
SNF_0116,Chapter 9: Security,7,Which of the following is supported by Snowflake for autoprovisioning of users and groups?,A. MFA,B. SCIM,C. FedRAMP,D. ITAR,,B,"SCIM is an open standard that enables automatic user provisioning and role syncing based on information from an identity provider With SCIM in place, when a new user is created in the identity provider the SCIM provisions the user in Snowflake SCIM can also sync groups created in an identity provider to roles in Snowflake"
SNF_0117,Chapter 9: Security,8,Which of the following are built-in roles provided by Snowflake? (Select all that apply.),A. SECURITYADMIN,B. ACCOUNTADMIN,C. PUBLIC,D. USERADMIN,E. LOADADMIN,ABCD,"Snowflake has the following built-in roles: ACCOUNTADMIN is the full-privilege account administrator role USERADMIN lets you create USERS and ROLES SECURITYADMIN inherits USERADMIN rights and can control global object grants SYSADMIN can build and manage most Snowflake objects PUBLIC is the most permissive role, since it is assigned to everyone"
SNF_0118,Chapter 9: Security,9,Which of the following access control methods are supported by Snowflake? (Select all that apply.),A. Attribute-based access control (ABAC),B. Role-based access control (RBAC),C. Discretionary access control (DAC),D. Redundant access control (RAC),,BC,"Snowflake's access control is built on the RBAC concept, where privileges are granted to roles and roles to users A role's privileges are inherited by all users in it Snowflake also supports discretionary access control (DAC), where the role creating an object owns it and can grant access to other roles"
SNF_0119,Chapter 9: Security,10,Which of the following statements are true regarding access control in Snowflake? (Select all that apply.),A. Securable objects are objects or entities to which privileges can be granted.,B. Roles cannot be granted to other roles.,C. Privileges are granted through the GRANT statement and taken away using the REVOKE statement.,D. Roles can be granted to other users or other roles.,,ACD,Securable objects are objects or entities to which privileges can be granted A set of privileges can be granted to each securable object The GRANT statement grants privileges while the REVOKE statement revokes them Privileges can only be granted to roles and cannot be granted directly to users A role is an entity to which privileges on other objects can be granted The roles themselves can then be granted to other users or other roles
SNF_0120,Chapter 9: Security,11,Which of the following are methods to implement column-level security in Snowflake? (Select two.),A. User policies,B. Dynamic data masking,C. Row-level policies,D. External tokenization,,BD,Snowflake provides masking policies that can be applied to columns to provide column-level security Column-level security is provided using dynamic data masking or through external tokenization
SNF_0121,Chapter 9: Security,12,"If an IP address is in both the block list and the allowed list in a network policy, what is Snowflake's behavior when enforcing the network policy?",A. The network policy is invalid as both the allowed and blocked lists cannot be populated.,"B. Snowflake applies the blocked list first, ensuring that the IP address is blocked from connecting, even if it is also defined in the allow list.","C. Snowflake applies the allowed list first, ensuring the IP address is allowed to connect, even if it is defined in the block list too.",D. The IP address is ignored.,,B,"Administrators can set network policies to enable or prevent access to specified IP v4 addresses In a network policy, there are three parts: name, authorized IP addresses, and blocked IP addresses If both the authorized and blocked lists are populated, Snowflake applies the blocked list first"
SNF_0122,Chapter 9: Security,13,What minimum Snowflake version is required for private connectivity to Snowflake?,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,C,"Through private connectivity, you can ensure that access to your Snowflake instance is over a private connection and can optionally block all Internet access Private connectivity to Snowflake requires a minimum of the Business Critical edition"
SNF_0123,Chapter 9: Security,14,"True or False: Snowflake encrypts all communication automatically using TLS 1.2, including communication for the Snowflake web UI, SnowSQL, and all the connectors and drivers.",A. True,B. False,,,,A,"Snowflake encrypts all data in transit using TLS 1 2 Encryption applies to all Snowflake connections, including the Snowflake web UI, JDBC, ODBC, and the Python Connector"
SNF_0124,Chapter 9: Security,15,Snowflake supports which of the following standards?,A. FedRAMP,B. BASEL II,C. IRAP – Protected,D. HIPAA,E. PCI DSS,ACDE,"Snowflake supports the following security and financial standards: SOC 1 Type II, SOC 2 Type II, PCI DSS, HIPAA, ISO/IEC 27001, FedRAMP Moderate, GxP, ITAR, and IRAP – Protected"
SNF_0125,Chapter 10: Account and Resource Management,1,"When configuring a resource monitor, which of the following are actions that can be configured? (Choose all that apply.)",A. Notify,B. Suspend and Notify,C. Suspend Immediately and Notify,D. Stop,,ABC,"You may notify, suspend and notify, or suspend immediately and notify virtual warehouses based on the percentage of usage of the credit quota When a resource monitor suspends a virtual warehouse, existing queries are allowed to complete On the other hand, suspending immediately stops the virtual warehouse immediately, terminating any queries"
SNF_0126,Chapter 10: Account and Resource Management,2,Which of the following statements are true regarding resource monitors? (Choose all that apply.),A. Resource monitors cannot be deleted once they have been created.,"B. If a resource monitor monitors a virtual warehouse, another resource monitor cannot monitor the same virtual warehouse.",C. Resource monitors can be configured to track multiple virtual warehouses.,"D. A resource monitor can be created at an account level, which means that the monitor tracks the credit usage at the whole account level, including all virtual warehouses' credit usage.",E. Only account administrators can create new resource monitors.,BCDE,"Resource monitors may be created at the account level, which means they track credit utilization across the entire account, encompassing credit usage across all virtual warehouses A resource monitor can track multiple virtual warehouses, but a virtual warehouse monitored by one resource monitor cannot be monitored by another resource monitor Finally, only account administrators can create new resource monitors, though they can provide additional roles, privileges to view and modify resource monitors"
SNF_0127,Chapter 10: Account and Resource Management,3,"True or False: Resource monitors can be used to control credit usage for serverless services such as cloud services, Snowpipe, or Auto Clustering.",A. True,B. False,,,,B,"Resource monitors can only suspend user-managed virtual warehouses Snowpipe, Automatic Reclustering, and Materialized View maintenance are serverless capabilities that resource monitors cannot track or control A resource monitor does not control cloud service charges"
SNF_0128,Chapter 10: Account and Resource Management,4,Which of the following privileges must be granted to other roles by the account administrator for other roles to see and modify resource monitors? (Choose all that apply.),A. READ,B. MODIFY,C. MONITOR,D. WRITE,,BC,"Only account administrators can create new resource monitors; however, once a resource monitor is created, the account administrator can provide MONITOR and MODIFY privileges to other roles to see and modify the resource monitor"
SNF_0129,Chapter 10: Account and Resource Management,5,Which of the following are valid methods through which account administrators can receive notifications generated by resource monitors? (Choose all that apply.),A. SQS notification,B. Snowflake web interface,C. Email,D. SMS notification,,BC,"Account administrators can receive notifications via email or the web interface However, the notifications are not enabled by default Therefore, each account administrator must enable and configure notification settings through preferences in the web interface to receive notifications"
SNF_0130,Chapter 10: Account and Resource Management,6,Which of the following can you use to view the last 365 days of the history of warehouse credit usage?,A. The WAREHOUSE_METERING_HISTORY view in the ACCOUNT_USAGE schema,B. The TABLE_STORAGE_METRICS view in the ACCOUNT_USAGE schema,C. The WAREHOUSE_METERING_HISTORY table function in the INFORMATION_SCHEMA schema,D. The TABLE_STORAGE_METRICS view in the INFORMATION_SCHEMA schema,,A,"INFORMATION_SCHEMA views are real time but do not have 365 days of retention The ACCOUNT_USAGE schema, on the other hand, has 365 days of history but is not real-time account usage WAREHOUSE_METERING_HISTORY is the correct view for this scenario"
SNF_0131,Chapter 10: Account and Resource Management,7,Which of the following statements are true regarding the ACCOUNT_USAGE schema? (Choose all that apply.),A. ACCOUNT_USAGE views can only have 7 days of history.,B. The data in ACCOUNT_USAGE views is real time.,C. The data in ACCOUNT_USAGE views can have a latency of 45 minutes up to 3 hours.,D. ACCOUNT_USAGE views can have 365 days of history.,,CD,"The data in ACCOUNT_USAGE views is not real time, and latency varies from 45 minutes to 3 hours The data in these views is kept for 365 days; thus, the last 365 days are always available"
SNF_0132,Chapter 10: Account and Resource Management,8,Which of the following statements are true regarding the INFORMATION_SCHEMA schema? (Choose all that apply.),A. Data in INFORMATION_SCHMEA has a latency of 3 hours.,B. Every database in Snowflake has an INFORMATION_SCHEMA schema.,C. Data in INFORMATION_SCHEMA is real time.,D. History retention of data in INFORMATION_SCHEMA varies from 7 days to 6 months.,E. INFORMATION_SCHEMA is a special schema found only under the Snowflake database.,BCD,"INFORMATION_SCHEMA is a special schema created automatically for every database created in Snowflake This schema acts as a data dictionary, providing metadata for database objects and views for account-level items like roles, databases, and warehouses Account-level storage, compute consumption, login history, and query history are available table functions in INFORMATION_SCHEMA The data in this schema is real time, and the historical data retention period in this schema ranges from 7 days to 6 months, depending on the view"
SNF_0133,Chapter 10: Account and Resource Management,9,"True or False: INFORMATION_SCHEMA provides several table functions that can be used to return account-level storage, compute usage, login history, and query history.",A. True,B. False,,,,A,"INFORMATION_SCHEMA is a special schema created automatically for every database created in Snowflake Account-level storage, compute consumption, login history, and query history are available table functions in this schema"
SNF_0134,Chapter 10: Account and Resource Management,10,You want to write a SQL query that shows successful and failed login attempts made in the last 10 minutes. Which of the following should you use?,A. ACCOUNT_USAGE.LOGIN_HISTORY view.,B. ACCOUNT_USAGE.ACCESS_HISTORY view.,C. The table function LOGIN_HISTORY in INFORMATION_SCHEMA.,D. It is not possible to view login attempts.,,C,"Since the requirement is to see data from the last 10 minutes, the ACCOUNT_USAGE schema cannot be used due to the latency associated with the ACCOUNT_USAGE schema Therefore, the table function LOGIN_HISTORY in INFORMATION_SCHEMA provides the required real-time information"
SNF_0135,Chapter 10: Account and Resource Management,11,Snowflake releases new features or bug fixes at what frequency?,A. Daily,B. Weekly,C. Monthly,D. Yearly,,B,"Every week, Snowflake releases new software The updates are transparent and cause no downtime or interruptions So that the consumer is constantly running the newest software release, automated releases deliver bug fixes, improvements, and new features"
SNF_0136,Chapter 10: Account and Resource Management,12,"When Snowflake releases new features or bug fixes, which accounts get the new software ahead of all other accounts?",A. Standard edition accounts,B. All Enterprise edition and above accounts,C. Business-critical accounts,D. Enterprise edition accounts that have opted for early access,,D,"Snowflake does not roll out a full release to all accounts at once; instead, accounts are updated gradually Accounts with Enterprise edition (or above) with early access get the new software first Standard editions may get the updates on day 1 or 2 of a software release Enterprise editions and above that have not opted for early access get the update on day 2"
